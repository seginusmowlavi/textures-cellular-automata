{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtBXvpaBmC5u",
        "outputId": "a9eba704-ee1c-4088-d30e-5b8f05394b01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device = cpu\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from PIL import Image\n",
        "\n",
        "from model import *\n",
        "from train import *\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import pickle\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'device = {device}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KZoN80tKmC52"
      },
      "source": [
        "# Load pretrained automaton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ-DUIKDmC53",
        "outputId": "6fea2a6a-7388-4a93-f476-dcd75d90ea56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CAutomaton(\n",
            "  (perception_filter): Conv2d(12, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (update_rule): Sequential(\n",
            "    (0): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(96, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "name = 'bubbles_bias_order012_mean_8000ep'\n",
        "\n",
        "automaton = CAutomaton(bias=True)\n",
        "automaton.load_state_dict(torch.load(f'pretrained_automata/{name}_state_dict.pt', map_location=device))\n",
        "#set_perception_kernels(automaton, angle=np.pi/2)\n",
        "\n",
        "print(automaton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.0025, -0.0026,  0.0033, -0.0005, -0.0010,  0.0006,  0.0199, -0.0014,\n",
              "         0.0030,  0.0087, -0.0038, -0.0080], requires_grad=True)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "automaton.update_rule[2].bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "ynAEm4O3y4_z",
        "outputId": "ac132bb7-3c2f-4bca-ccb0-4d5b64ad0241"
      },
      "outputs": [],
      "source": [
        "# load loss data\n",
        "\n",
        "with open(f'pretrained_automata/{name}_tlosses.pickle', 'rb') as f:\n",
        "    texture_losses = pickle.load(f)\n",
        "with open(f'pretrained_automata/{name}_dlosses.pickle', 'rb') as f:\n",
        "    domain_losses = pickle.load(f)\n",
        "with open(f'pretrained_automata/{name}_losses.pickle', 'rb') as f:\n",
        "    losses = pickle.load(f)\n",
        "\n",
        "# plot evolution\n",
        "\n",
        "plt.semilogy(losses, ',', color='C2', label='total loss')\n",
        "plt.semilogy(texture_losses, ',', color='C0', label='texture loss')\n",
        "plt.semilogy(domain_losses, ',', color='C1', label='domain_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(losses[200:], '.', color='C2', label='total loss')\n",
        "plt.plot(texture_losses[200:], '.', color='C0', label='texture loss')\n",
        "plt.plot(domain_losses[200:], '.', color='C1', label='domain_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrtQEjvRyDS5"
      },
      "source": [
        "# Test automaton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FkYhW3KSJEDB"
      },
      "outputs": [],
      "source": [
        "size = (128, 128)\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "if os.path.exists('outputs'):\n",
        "    shutil.rmtree('outputs')\n",
        "    os.mkdir('outputs')\n",
        "else:\n",
        "    os.mkdir('outputs')\n",
        "\n",
        "test_iters = 500\n",
        "\n",
        "# iterate automaton from random initial state\n",
        "with torch.inference_mode():\n",
        "    #states = torch.rand((1, automaton.num_states, *size), device=device)\n",
        "    states = 0.5*torch.ones((1, automaton.num_states, *size), device=device) + 0.05*torch.randn((1, automaton.num_states, *size), device=device)\n",
        "    for step in range(test_iters):\n",
        "        states = automaton(states)\n",
        "        img = states[:, :3, :, :]\n",
        "\n",
        "        save_image(img[0], f'outputs/epoch_{step:05}.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4EP53-0A-rEK"
      },
      "outputs": [],
      "source": [
        "# Make a gif animation\n",
        "def make_gif(test_iters, name):\n",
        "    frames = [Image.open(f'outputs/epoch_{iter:05}.png') for iter in range(test_iters)]\n",
        "    frame_one = frames[0]\n",
        "    frame_one.save(f\"gifs/{name}_turinginit_{size[0]}p_{test_iters}iter_evolution.gif\", format=\"GIF\", append_images=frames,\n",
        "               save_all=True, duration=10, loop=0)\n",
        "\n",
        "make_gif(test_iters, name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First order terms?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 256\n",
        "\n",
        "x = torch.linspace(0, 1, n)[None, None, :, None].expand((1, 12, n, n))\n",
        "y = torch.linspace(0, 1, n)[None, None, None, :].expand((1, 12, n, n))\n",
        "\n",
        "for i in range(50):\n",
        "    wx, wy, p = torch.rand((12)), torch.rand((12)), torch.rand((12))\n",
        "    wx = (wx/wx.sum())[None, :, None, None].expand((1, 12, n, n))\n",
        "    wy = (wy/wy.sum())[None, :, None, None].expand((1, 12, n, n))\n",
        "    p = p[None, :, None, None].expand((1, 12, n, n))\n",
        "    states = p*wx*x+(1-p)*wy*y\n",
        "    print((automaton(states)-states).abs().max().item())\n",
        "    #print((automaton(states)-states).abs().mean().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
